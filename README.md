### Configura√ß√£o Atual de Valida√ß√£o:

  N_SAMPLES = 800
  test_size = 0.2  # 20% para teste final

  ---
  1. Simple Temporal Split

  Passo a Passo:

  - Etapa 1: Separa√ß√£o Inicial (Data Leakage Prevention)
  Dataset (800) ‚Üí split_for_optimization()
  ‚îú‚îÄ Otimiza√ß√£o: 640 amostras (80%) ‚Üê X_optim, y_optim
  ‚îî‚îÄ Teste Final: 160 amostras (20%) ‚Üê X_test, y_test (ISOLADOS)

  - Etapa 2: Subdivis√£o para Valida√ß√£o
  Dados de Otimiza√ß√£o (640) ‚Üí temporal_split()
  ‚îú‚îÄ Treino: 480 amostras (75% de 640) ‚Üê X_train, y_train  
  ‚îî‚îÄ Valida√ß√£o: 160 amostras (25% de 640) ‚Üê X_val, y_val

  - Etapa 3: Otimiza√ß√£o (20 trials)
  Para cada trial do Optuna:
  1. Sugere hiperpar√¢metros (LSTM units, dropout, lr, batch_size)
  2. Cria modelo com esses hiperpar√¢metros
  3. Treina modelo:
     - Dados: X_train (480), y_train (480)
     - Valida√ß√£o: X_val (160), y_val (160) 
     - Early stopping baseado em val_loss
  4. Calcula RMSE na valida√ß√£o
  5. Retorna RMSE para Optuna otimizar

  - Etapa 4: Modelo Final
  1. Pega melhores hiperpar√¢metros encontrados
  2. Cria modelo final com esses par√¢metros
  3. Treina com TODOS os dados de otimiza√ß√£o:
     - X_optim (640), y_optim (640)
     - 100 epochs sem early stopping
  4. Avalia no teste final: X_test (160), y_test (160)

  ---
  2. Walk-Forward Validation

  Passo a Passo:

  - Etapa 1: Separa√ß√£o Inicial (igual)
  Dataset (800) ‚Üí 640 otimiza√ß√£o + 160 teste final

  - Etapa 2: N√£o h√° subdivis√£o pr√©via
  X_train, X_val = None (n√£o usados)
  Trabalha direto com X_optim (640), y_optim (640)

  - Etapa 3: Otimiza√ß√£o (20 trials)
  Para cada trial do Optuna:
  1. Sugere hiperpar√¢metros
  2. Executa walk_forward_validation():

     Janela m√≥vel de 100 amostras:
     ‚îú‚îÄ Ponto 100: treina[0:100] ‚Üí prediz[100]
     ‚îú‚îÄ Ponto 101: treina[1:101] ‚Üí prediz[101]
     ‚îú‚îÄ Ponto 102: treina[2:102] ‚Üí prediz[102]
     ‚îú‚îÄ ...
     ‚îî‚îÄ Ponto 639: treina[539:639] ‚Üí prediz[639]

     Total: 540 predi√ß√µes individuais
  3. Calcula RMSE m√©dio das 540 predi√ß√µes
  4. Retorna para Optuna

  - Etapa 4: Modelo Final (igual Simple Temporal)
  1. Treina com todos os dados de otimiza√ß√£o (640)
  2. Testa em dados isolados (160)

  ---
  3. Time Series Cross-Validation

  Passo a Passo:

  - Etapa 1: Separa√ß√£o Inicial (igual)
  Dataset (800) ‚Üí 640 otimiza√ß√£o + 160 teste final

  - Etapa 2: N√£o h√° subdivis√£o pr√©via
  Trabalha direto com X_optim (640), y_optim (640)

  - Etapa 3: Otimiza√ß√£o (20 trials)
  Para cada trial do Optuna:
  1. Sugere hiperpar√¢metros
  2. Executa time_series_cross_validate():

     3 folds crescentes:
     ‚îú‚îÄ Fold 1: treina[0:320] ‚Üí valida[320:427]
     ‚îú‚îÄ Fold 2: treina[0:427] ‚Üí valida[427:533]  
     ‚îî‚îÄ Fold 3: treina[0:533] ‚Üí valida[533:640]
     
     Para cada fold:
     - Cria modelo novo
     - Treina com dados do fold
     - Avalia na valida√ß√£o do fold
     - Calcula RMSE individual
     
  3. RMSE final = m√©dia dos 3 RMSEs
  4. Retorna para Optuna

  - Etapa 4: Modelo Final (igual)
  1. Treina com todos os dados de otimiza√ß√£o (640)
  2. Testa em dados isolados (160)


---


  üîß PAR√ÇMETROS B√ÅSICOS DO MODELO

  SEQUENCE_LENGTH = 30

  O que √©: Quantos pontos hist√≥ricos o modelo usa para fazer uma predi√ß√£o
  Exemplo pr√°tico:
  - Se voc√™ tem dados de vaz√£o di√°rios e SEQUENCE_LENGTH = 30
  - O modelo usa os √∫ltimos 30 dias para prever o dia 31
  - Como uma "janela deslizante" de 30 dias

  N_FEATURES = 2

  O que √©: N√∫mero de vari√°veis de entrada (caracter√≠sticas)
  Exemplo pr√°tico:
  - Feature 1: Precipita√ß√£o (mm)
  - Feature 2: Temperatura (¬∞C)
  - O modelo usa essas 2 vari√°veis para prever a vaz√£o

  ---
  üìà CONFIGURA√á√ïES DE DADOS

  N_SAMPLES = 800

  O que √©: Quantidade total de amostras sint√©ticas geradas
  Exemplo pr√°tico:
  - 800 dias de dados simulados de vaz√£o
  - Em desenvolvimento: 200 (mais r√°pido para testar)
  - Em produ√ß√£o: 800 (mais dados = melhor modelo)

  ---
  üéØ OTIMIZA√á√ÉO OPTUNA

  n_trials = 20

  O que √©: Quantas combina√ß√µes de hiperpar√¢metros testar
  Exemplo pr√°tico:
  Trial 1: 64 neur√¥nios, dropout=0.2, lr=0.005
  Trial 2: 96 neur√¥nios, dropout=0.3, lr=0.001
  ...
  Trial 20: 128 neur√¥nios, dropout=0.1, lr=0.008
  Resultado: Escolhe a melhor combina√ß√£o automaticamente

  ---
  üèãÔ∏è CONFIGURA√á√ïES DE TREINAMENTO

  epochs = 50

  O que √©: Quantas vezes o modelo v√™ todos os dados durante otimiza√ß√£o
  Exemplo pr√°tico:
  - 50 √©pocas = modelo passa 50 vezes pelos 800 dados
  - Menos √©pocas = treinamento r√°pido mas pode n√£o aprender bem
  - Mais √©pocas = aprende melhor mas demora mais

  final_epochs = 100

  O que √©: √âpocas para treinar o modelo final (ap√≥s otimiza√ß√£o)
  Por que √© maior: Modelo final usa os melhores par√¢metros, ent√£o pode treinar mais

  ---
  ‚úÖ CONFIGURA√á√ïES DE VALIDA√á√ÉO

  method = 'time_series_cv'

  Op√ß√µes dispon√≠veis:
  - 'temporal_split': Divide dados em sequ√™ncia (60% treino, 20% val, 20% teste)
  - 'time_series_cv': Valida√ß√£o cruzada temporal (3 dobras)
  - 'walk_forward': Simula predi√ß√£o em tempo real

  Exemplo time_series_cv:
  Fold 1: [1-200] treino ‚Üí [201-300] valida√ß√£o
  Fold 2: [1-300] treino ‚Üí [301-400] valida√ß√£o
  Fold 3: [1-400] treino ‚Üí [401-500] valida√ß√£o

  test_size = 0.2

  O que √©: 20% dos dados reservados para teste final
  Exemplo: De 800 dados, 160 ficam separados e NUNCA s√£o vistos durante treinamento

  cv_splits = 3

  O que √©: N√∫mero de dobras na valida√ß√£o cruzada
  Mais dobras = valida√ß√£o mais robusta, mas demora mais

  walk_forward_window = 100

  O que √©: Tamanho da janela para valida√ß√£o walk-forward
  Exemplo:
  Treina com dados 1-100 ‚Üí prediz 101
  Treina com dados 2-101 ‚Üí prediz 102
  Treina com dados 3-102 ‚Üí prediz 103

  ---
  üß† LIMITES DOS HIPERPAR√ÇMETROS LSTM

  units_min/max = 32-128

  O que √©: Quantidade de neur√¥nios nas camadas LSTM
  Exemplo pr√°tico:
  - 32 neur√¥nios: modelo simples, r√°pido, pode n√£o capturar padr√µes complexos
  - 128 neur√¥nios: modelo complexo, lento, captura padr√µes sutis
  - Optuna testa valores entre 32 e 128

  dropout_min/max = 0.1-0.5

  O que √©: Preven√ß√£o de overfitting
  Exemplo pr√°tico:
  - dropout=0.1: "desliga" 10% dos neur√¥nios aleatoriamente
  - dropout=0.5: "desliga" 50% dos neur√¥nios
  - Evita que o modelo "decore" os dados de treino

  lr_min/max = 0.001-0.01

  O que √©: Taxa de aprendizado (learning rate)
  Exemplo pr√°tico:
  - lr=0.001: aprende devagar mas com mais precis√£o
  - lr=0.01: aprende r√°pido mas pode "passar do ponto"
  - Como a velocidade de um carro: muito devagar demora, muito r√°pido pode bater

  batch_sizes = [16, 32, 64]

  O que √©: Quantos exemplos o modelo processa por vez
  Exemplo pr√°tico:
  - batch_size=16: processa 16 sequ√™ncias por vez
  - batch_size=64: processa 64 sequ√™ncias por vez
  - Maior batch = mais r√°pido mas usa mais mem√≥ria

  ---
  ‚èπÔ∏è CALLBACKS (CONTROLES DE TREINAMENTO)

  early_stopping_patience = 15

  O que √©: Para o treinamento se n√£o melhorar por 15 √©pocas
  Exemplo: Se por 15 √©pocas seguidas o erro n√£o diminuir, para de treinar

  lr_reduction_patience = 10

  O que √©: Reduz learning rate se n√£o melhorar por 10 √©pocas
  Exemplo: Se estagnar por 10 √©pocas, reduz lr de 0.01 para 0.005

  lr_reduction_factor = 0.5

  O que √©: Fator de redu√ß√£o do learning rate
  Exemplo: Multiplica lr por 0.5 (reduz pela metade)

  ---
  üî¨ VALIDA√á√ÉO ESPEC√çFICA

  cv_epochs = 30

  O que √©: √âpocas usadas durante valida√ß√£o cruzada (menor que o treino final)
  Por que menos: Valida√ß√£o cruzada testa muitas combina√ß√µes, ent√£o usa menos √©pocas para ser mais r√°pido

  walk_forward_epochs = 10

  O que √©: √âpocas para cada janela do walk-forward
  Por que t√£o pouco: Walk-forward treina muitos mini-modelos, ent√£o cada um treina rapidamente

  walk_forward_batch_size = 16

  O que √©: Batch size espec√≠fico para walk-forward
  Menor porque: Janelas menores de dados precisam de batch menor
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from ..utils.validation import TimeSeriesValidator
from config.config import Config


class OperationalEarlyStopping(tf.keras.callbacks.Callback):
    """
    Early stopping baseado em performance operacional para contexto hidroel√©trico

    Para training stops se horizontes cr√≠ticos (dias 1-3) come√ßarem a degradar
    mesmo que a loss geral ainda esteja melhorando
    """

    def __init__(self, patience=5, min_delta=0.001, verbose=1):
        super().__init__()
        self.patience = patience
        self.min_delta = min_delta
        self.verbose = verbose
        self.wait = 0
        self.best_critical_performance = float('inf')
        self.horizon = Config.PREDICTION.get('horizon', 1)

    def on_epoch_end(self, epoch, logs=None):
        if self.horizon == 1:
            # Single-step: usar loss de valida√ß√£o padr√£o
            current_performance = logs.get('val_loss', float('inf'))
        else:
            # Multi-step: focar em performance dos primeiros horizontes
            # Como n√£o temos m√©tricas separadas por horizonte durante training,
            # usar val_loss como proxy e aplicar early stopping mais conservador
            current_performance = logs.get('val_loss', float('inf'))

        # Verificar se houve melhoria significativa
        if current_performance < self.best_critical_performance - self.min_delta:
            self.best_critical_performance = current_performance
            self.wait = 0
            if self.verbose:
                print(f"\\n  üü¢ √âpoca {epoch+1}: Performance operacional melhorou para {current_performance:.6f}")
        else:
            self.wait += 1
            if self.verbose:
                print(f"\\n  üü° √âpoca {epoch+1}: Sem melhoria cr√≠tica h√° {self.wait} √©pocas (performance: {current_performance:.6f})")

            if self.wait >= self.patience:
                if self.verbose:
                    print(f"\\n  üî¥ EARLY STOPPING OPERACIONAL: Performance cr√≠tica n√£o melhorou h√° {self.patience} √©pocas")
                    print(f"     Melhor performance: {self.best_critical_performance:.6f}")
                    print(f"     Performance atual: {current_performance:.6f}")
                    print(f"     Parando treinamento para preservar qualidade operacional")
                self.model.stop_training = True


class HydroelectricCallback(tf.keras.callbacks.Callback):
    """
    Callback especializado para monitoramento de treinamento hidroel√©trico

    Fornece insights sobre degrada√ß√£o de performance por horizonte durante treinamento
    """

    def __init__(self, validation_data=None, verbose=1):
        super().__init__()
        self.validation_data = validation_data
        self.verbose = verbose
        self.horizon = Config.PREDICTION.get('horizon', 1)
        self.epoch_history = []

    def on_epoch_end(self, epoch, logs=None):
        if self.validation_data is None or self.horizon == 1:
            return

        X_val, y_val = self.validation_data

        # Fazer predi√ß√µes para an√°lise
        try:
            y_pred = self.model.predict(X_val, verbose=0)

            # Calcular RMSE por horizonte
            horizon_rmses = []
            for h in range(min(3, self.horizon)):  # Focar nos primeiros 3 dias
                rmse_h = np.sqrt(mean_squared_error(y_val[:, h], y_pred[:, h]))
                horizon_rmses.append(rmse_h)

            self.epoch_history.append({
                'epoch': epoch + 1,
                'horizon_rmses': horizon_rmses,
                'avg_critical_rmse': np.mean(horizon_rmses)
            })

            # Log peri√≥dico (a cada 10 √©pocas ou √∫ltimas 5)
            if self.verbose and (epoch % 10 == 0 or epoch >= logs.get('epochs', 50) - 5):
                print(f"\\n  üìä √âpoca {epoch+1} - RMSE Cr√≠tico (D1-3): {np.mean(horizon_rmses):.4f}")
                if len(horizon_rmses) > 1:
                    degradation = horizon_rmses[-1] / horizon_rmses[0]
                    print(f"     Degrada√ß√£o D1‚ÜíD3: {degradation:.2f}x")

        except Exception as e:
            if self.verbose:
                print(f"\\n  ‚ö†Ô∏è Erro no monitoramento hidroel√©trico: {e}")


class LSTMModel:
    def __init__(self, sequence_length=30, n_features=2):
        self.sequence_length = sequence_length
        self.n_features = n_features
        self.scaler_X = MinMaxScaler()
        self.scaler_y = MinMaxScaler()
        self.model = None
        self.validator = TimeSeriesValidator(test_size=Config.VALIDATION['test_size'])

    def prepare_sequences(self, data, target_col='vazao'):
        """
        Prepara sequ√™ncias para predi√ß√£o multi-step sem data leakage

        Para horizon=1: [30 steps hist√≥ricos] ‚Üí [step t+1]
        Para horizon=7: [30 steps hist√≥ricos] ‚Üí [steps t+1, t+2, ..., t+7]

        Args:
            data: DataFrame com dados temporais
            target_col: Nome da coluna target

        Returns:
            X: Sequ√™ncias de entrada (n_samples, sequence_length, n_features)
            y: Targets (n_samples,) para horizon=1 ou (n_samples, horizon) para horizon>1
        """
        features = data.drop(columns=[target_col])
        target = data[target_col].values  # N√£o fazer reshape ainda

        features_scaled = self.scaler_X.fit_transform(features)
        target_scaled = self.scaler_y.fit_transform(target.reshape(-1, 1)).flatten()

        horizon = Config.PREDICTION['horizon']
        X, y = [], []

        print(f"DEBUG: Preparando sequ√™ncias com horizon={horizon}")
        print(f"DEBUG: Dados totais: {len(data)} amostras")

        # Loop corrigido: garantir que n√£o h√° vazamento temporal
        for i in range(self.sequence_length, len(data) - horizon + 1):
            # Input: sequ√™ncia hist√≥rica (30 dias ANTES de i)
            X.append(features_scaled[i-self.sequence_length:i])

            # Output: pr√≥ximos 'horizon' dias A PARTIR de i
            if horizon == 1:
                y.append(target_scaled[i])  # Apenas dia i
            else:
                y.append(target_scaled[i:i+horizon])  # Dias i at√© i+horizon-1

        print(f"DEBUG: Sequ√™ncias criadas - X: {len(X)}, y: {len(y)}")
        if len(y) > 0:
            if horizon == 1:
                print(f"DEBUG: Shape y[0]: {np.array(y[0]).shape}")
            else:
                print(f"DEBUG: Shape y[0]: {np.array(y[0]).shape} (deve ser {horizon})")

        return np.array(X), np.array(y)

    def create_model(self, params):
        lstm_units, dropout_rate, learning_rate, batch_size_idx = params
        lstm_units = int(lstm_units)
        horizon = Config.PREDICTION['horizon']

        model = Sequential([
            Input(shape=(self.sequence_length, self.n_features)),
            LSTM(lstm_units, return_sequences=True),
            Dropout(dropout_rate),
            LSTM(lstm_units // 2, return_sequences=False),
            Dropout(dropout_rate),
            Dense(25, activation='relu'),
            Dense(horizon)  # Outputs configur√°veis baseados no horizon
        ])

        optimizer = Adam(learning_rate=learning_rate)
        model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])

        return model

    def _proper_denormalize_multistep(self, y_scaled, horizon):
        """
        Desnormaliza√ß√£o correta para predi√ß√µes multi-step

        Args:
            y_scaled: Dados escalados (n_samples, horizon) ou (n_samples,)
            horizon: N√∫mero de horizontes de predi√ß√£o

        Returns:
            array: Dados desnormalizados no formato original
        """
        if horizon == 1:
            # Caso simples: 1D ou 2D com 1 coluna
            if len(y_scaled.shape) == 1:
                return self.scaler_y.inverse_transform(y_scaled.reshape(-1, 1)).flatten()
            else:
                return self.scaler_y.inverse_transform(y_scaled.reshape(-1, 1)).flatten()
        else:
            # Multi-step: desnormalizar cada horizonte separadamente
            n_samples = y_scaled.shape[0]
            y_denorm = np.zeros((n_samples, horizon))

            for h in range(horizon):
                y_denorm[:, h] = self.scaler_y.inverse_transform(
                    y_scaled[:, h].reshape(-1, 1)
                ).flatten()

            return y_denorm

    def _calculate_metrics_simple(self, y_true, y_pred, prefix=''):
        """
        C√°lculo de m√©tricas simplificado e intuitivo com desnormaliza√ß√£o correta

        Args:
            y_true: Valores reais escalados
            y_pred: Valores preditos escalados
            prefix: Prefixo para as m√©tricas ('test', 'val', etc.)

        Returns:
            dict: M√©tricas calculadas
        """
        horizon = Config.PREDICTION['horizon']

        if horizon == 1:
            # Caso simples: predi√ß√£o de 1 passo
            y_true_orig = self._proper_denormalize_multistep(y_true, horizon)
            y_pred_orig = self._proper_denormalize_multistep(y_pred, horizon)

            metrics = {
                f'{prefix}_rmse' if prefix else 'rmse': np.sqrt(mean_squared_error(y_true_orig, y_pred_orig)),
                f'{prefix}_mae' if prefix else 'mae': mean_absolute_error(y_true_orig, y_pred_orig),
                f'{prefix}_r2' if prefix else 'r2': r2_score(y_true_orig, y_pred_orig)
            }

            print(f"RESULTADO {prefix.upper()}: Predi√ß√£o de 1 step - RMSE: {metrics[f'{prefix}_rmse' if prefix else 'rmse']:.3f}")

        else:
            # Caso multi-step: m√©tricas por horizonte + geral
            # Desnormaliza√ß√£o correta
            y_true_orig = self._proper_denormalize_multistep(y_true, horizon)
            y_pred_orig = self._proper_denormalize_multistep(y_pred, horizon)

            # M√©trica geral (todos os horizontes) - PONDERADA para contexto hidroel√©trico
            weights = self._get_hydroelectric_weights(horizon)
            rmse_weighted = self._calculate_weighted_rmse(y_true_orig, y_pred_orig, weights)
            rmse_overall = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))  # Para compara√ß√£o
            mae_overall = mean_absolute_error(y_true_orig, y_pred_orig)
            r2_overall = r2_score(y_true_orig.flatten(), y_pred_orig.flatten())

            metrics = {
                f'{prefix}_rmse_weighted' if prefix else 'rmse_weighted': rmse_weighted,
                f'{prefix}_rmse' if prefix else 'rmse': rmse_overall,
                f'{prefix}_mae' if prefix else 'mae': mae_overall,
                f'{prefix}_r2' if prefix else 'r2': r2_overall
            }

            print(f"\\nRESULTADO {prefix.upper()}: Predi√ß√£o de {horizon} dias consecutivos")
            print(f"RMSE Ponderado (Hidroel√©trico): {rmse_weighted:.3f}")
            print(f"RMSE Geral (N√£o-ponderado): {rmse_overall:.3f}")

            # M√©tricas por horizonte (dias individuais)
            print("RMSE por dia:")
            for h in range(horizon):
                rmse_h = np.sqrt(mean_squared_error(y_true_orig[:, h], y_pred_orig[:, h]))
                mae_h = mean_absolute_error(y_true_orig[:, h], y_pred_orig[:, h])
                r2_h = r2_score(y_true_orig[:, h], y_pred_orig[:, h])

                metrics[f'{prefix}_rmse_day{h+1}' if prefix else f'rmse_day{h+1}'] = rmse_h
                metrics[f'{prefix}_mae_day{h+1}' if prefix else f'mae_day{h+1}'] = mae_h
                metrics[f'{prefix}_r2_day{h+1}' if prefix else f'r2_day{h+1}'] = r2_h

                weight_info = f" (peso: {weights[h]:.2f})" if horizon > 1 else ""
                print(f"  Dia {h+1} (t+{h+1}): RMSE={rmse_h:.3f}, MAE={mae_h:.3f}, R¬≤={r2_h:.3f}{weight_info}")

        return metrics

    def _get_hydroelectric_weights(self, horizon):
        """
        Pesos operacionais para contexto hidroel√©trico

        Prioriza predi√ß√µes de curto prazo (dias 1-3) que s√£o cr√≠ticas
        para decis√µes operacionais imediatas
        """
        if horizon == 1:
            return np.array([1.0])

        # Peso exponencial decrescente: dias iniciais s√£o mais cr√≠ticos
        weights = np.exp(-0.15 * np.arange(horizon))

        # Manter pesos normalizados (soma = 1) para m√©dia ponderada correta
        weights = weights / weights.sum()

        return weights

    def _calculate_weighted_rmse(self, y_true, y_pred, weights):
        """
        Calcula RMSE ponderado por horizonte para otimiza√ß√£o hidroel√©trica

        Retorna m√©dia ponderada dos RMSEs, n√£o soma, para manter escala correta
        """
        horizon_rmses = []
        for h in range(y_true.shape[1]):
            rmse_h = np.sqrt(mean_squared_error(y_true[:, h], y_pred[:, h]))
            horizon_rmses.append(rmse_h)

        # M√©dia ponderada: Œ£(rmse_h * weight_h) onde Œ£(weight_h) = 1
        weighted_rmse = np.average(horizon_rmses, weights=weights)

        return weighted_rmse

    def debug_shapes_and_predictions(self, X, y):
        """
        Fun√ß√£o de debugging para verificar shapes e exemplo de predi√ß√µes
        """
        horizon = Config.PREDICTION['horizon']

        print(f"\n{'='*60}")
        print(f"DEBUG: SHAPES E PREDI√á√ïES (horizon={horizon})")
        print(f"{'='*60}")

        print(f"X shape: {X.shape}")
        print(f"y shape: {y.shape}")

        if len(y.shape) == 1:
            print(f"y √© 1D - cada amostra prediz 1 valor")
        else:
            print(f"y √© 2D - cada amostra prediz {y.shape[1]} valores")

        # Exemplo de uma sequ√™ncia
        print(f"\nEXEMPLO - Primeira sequ√™ncia:")
        print(f"Input (√∫ltimos 5 dias de features): {X[0][-5:]}")
        if horizon == 1:
            print(f"Target: {y[0]} (pr√≥ximo dia)")
        else:
            print(f"Target: {y[0]} (pr√≥ximos {horizon} dias)")

        # Verificar se h√° algum modelo treinado
        if self.model is not None:
            print(f"\nTESTE DE PREDI√á√ÉO:")
            test_pred = self.model.predict(X[:3])  # Primeiras 3 amostras
            print(f"Predi√ß√£o shape: {test_pred.shape}")
            print(f"Predi√ß√µes: {test_pred}")

        print(f"{'='*60}\n")

    def train(self, X, y, params, epochs=None):
        epochs = epochs or Config.TRAINING['final_epochs']

        # DEBUG: Verificar shapes antes do treinamento
        self.debug_shapes_and_predictions(X, y)

        # Usar divis√£o temporal estruturada
        X_train, X_val, X_test, y_train, y_val, y_test = self.validator.temporal_split(X, y)

        print(f"Divis√£o temporal final:")
        print(f"   Train: {len(X_train)} amostras ({len(X_train)/len(X)*100:.1f}%)")
        print(f"   Val: {len(X_val)} amostras ({len(X_val)/len(X)*100:.1f}%)")
        print(f"   Test: {len(X_test)} amostras ({len(X_test)/len(X)*100:.1f}%)")

        self.model = self.create_model(params)
        batch_size = Config.LSTM_PARAMS_BOUNDS['batch_sizes'][int(params[3])]

        # Callbacks operacionais para contexto hidroel√©trico
        callbacks_list = [
            # Early stopping padr√£o
            tf.keras.callbacks.EarlyStopping(
                patience=Config.CALLBACKS['early_stopping_patience'],
                restore_best_weights=True,
                verbose=1
            ),
            # Redu√ß√£o de learning rate
            tf.keras.callbacks.ReduceLROnPlateau(
                patience=Config.CALLBACKS['lr_reduction_patience'],
                factor=Config.CALLBACKS['lr_reduction_factor'],
                verbose=1
            ),
            # Early stopping operacional (prioriza horizontes cr√≠ticos)
            OperationalEarlyStopping(
                patience=Config.CALLBACKS['early_stopping_patience'] - 2,  # Mais conservador
                min_delta=0.0001,
                verbose=1
            ),
            # Monitoramento hidroel√©trico
            HydroelectricCallback(
                validation_data=(X_val, y_val),
                verbose=1
            )
        ]

        print(f"\\nüè≠ TREINAMENTO HIDROEL√âTRICO:")
        print(f"   Early Stopping Padr√£o: {Config.CALLBACKS['early_stopping_patience']} √©pocas")
        print(f"   Early Stopping Operacional: {Config.CALLBACKS['early_stopping_patience'] - 2} √©pocas")
        print(f"   Monitoramento por horizonte: {'Ativo' if Config.PREDICTION['horizon'] > 1 else 'Inativo'}")
        print(f"   {'='*50}")

        history = self.model.fit(
            X_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_data=(X_val, y_val),
            callbacks=callbacks_list,
            verbose=1
        )

        # Avaliar no conjunto de teste (nunca visto)
        y_pred = self.model.predict(X_test)
        horizon = Config.PREDICTION['horizon']

        print(f"\nDEBUG: Avalia√ß√£o com horizon={horizon}")
        print(f"DEBUG: y_test shape: {y_test.shape}")
        print(f"DEBUG: y_pred shape: {y_pred.shape}")

        # Calcular m√©tricas de forma simplificada
        metrics = self._calculate_metrics_simple(y_test, y_pred, 'test')

        # Tamb√©m calcular m√©tricas na valida√ß√£o para compara√ß√£o
        y_val_pred = self.model.predict(X_val)
        val_metrics = self._calculate_metrics_simple(y_val, y_val_pred, 'val')

        # Combinar m√©tricas
        all_metrics = {**metrics, **val_metrics}

        return history, all_metrics

    @tf.function(reduce_retracing=True)
    def _predict_function(self, X):
        return self.model(X, training=False)

    def predict(self, X):
        if self.model is None:
            raise ValueError("Modelo n√£o foi treinado ainda!")

        predictions = self._predict_function(X)
        horizon = Config.PREDICTION['horizon']

        # Usar desnormaliza√ß√£o correta
        predictions_numpy = predictions.numpy() if hasattr(predictions, 'numpy') else predictions
        return self._proper_denormalize_multistep(predictions_numpy, horizon)